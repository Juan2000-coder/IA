{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWUX78DM7n9T"
      },
      "source": [
        "# Trabajo Práctico Nº1\n",
        "\n",
        "---\n",
        "\n",
        "<h2>Integrantes:\n",
        "\n",
        "  > *Borquez Juan*\n",
        "\n",
        "  > *Escobar Matías*\n",
        "\n",
        "  > *Hase Stephan*\n",
        "\n",
        "  > *Miranda Francisco*\n",
        "\n",
        "  > *Panonto Valentín*\n",
        "\n",
        "<h2> Temas Tratados en el Trabajo Práctico\n",
        "\n",
        "* Diferencia entre Inteligencia e Inteligencia Artificial.\n",
        "\n",
        "* Concepto de omnisciencia, aprendizaje y autonomía.\n",
        "\n",
        "* Definición de Agente y sus características. Clasificación de Agentes según su estructura.\n",
        "\n",
        "* Identificación y categorización del Entorno de Trabajo en tabla REAS.\n",
        "\n",
        "* Caracterización del Entorno de Trabajo.\n",
        "\n",
        "<h2>Anotaciones\n",
        "\n",
        "<h2>Ejercicios Teóricos\n",
        "\n",
        "1. Defina con sus propias palabras inteligencia natural, inteligencia artificial y agente.\n",
        "\n",
        "  - **Inteligencia Natural**: Capacidad de las cosas de responder ante estímulos. Inteligencia que poseen los seres vivos.\n",
        "\n",
        "  - **Inteligencia artificial**: Creación que puede relacionarse con su entorno a través de sensores y actuadores, con un propósito específico.\n",
        "\n",
        "  - **Agente**: Individuo que realiza una acción.\n",
        "\n",
        "2. ¿Qué es un agente racional?\n",
        "\n",
        "Es aquel agente que busca, a partir de sus acciones, obtener el mejor resultado posible.\n",
        "3. ¿Un agente es siempre una computadora?\n",
        "\n",
        "No necesariamente. Un ejemplo de agente, que no sea una computadora, puede ser un ser vivo.\n",
        "\n",
        "4. Defina Omnisciencia, Aprendizaje y Autonomía.\n",
        "\n",
        "  - **Omnisciencia**: Es cuando se sabe todo sobre algún tema en particular. Cabe destacar que esto es imposible.\n",
        "\n",
        "  - **Aprendizaje**: Proceso por el cual un agente cambia su manera de actuar en base a experiencias pasadas.\n",
        "  \n",
        "  - **Autonomía**: Capacidad del agente de funcionar, sin ningún tipo de supervisión.\n",
        "\n",
        "5. Defina cada tipo de agente en función de su **estructura** y dé un ejemplo de cada categoría.\n",
        "\n",
        "  **Agentes reactivos**\n",
        "\n",
        "  - Simple: Agentes que reaccionan ante ciertos estímulos del entorno. Ejemplo: luces automáticas.\n",
        "\n",
        "  - Basado en modelos: Agentes que tienen un comportamiento que responde según una máquina de estados. El agente se colocará en un estado u otro, en función del estímulo que se le dé. Esto hace que no reaccione inmediatamente, sino que tenga un procesamiento interno antes de dar una respuesta. Ejemplo: funcionamiento del lavarropas para agregar agua o jabón al sistema, estando el lavarropas en funcionamiento, pero no el proceso de lavado terminado.\n",
        "\n",
        "  **Agentes No reactivos**\n",
        "\n",
        "  - Basado en objetivos: Este agente tiene un objetivo a alcanzar (una configuración del entorno determinada), y para ello, realiza una planificación antes de actuar. Ejemplo: establecimiento de setpoints en sistemas PID.\n",
        "\n",
        "  - Basados en utilidad: Agentes que tratan de alcanzar un objetivo determinado, pero a diferencia de los basados en objetivos, estos intentan alcanzarlo de la manera más eficiente posible. Ejemplo: Recomendaciones realizadas por el GPS, el cual no muestra todas las rutas que pudo construir, sino que muestra una selección de las más provechosas.\n",
        "\n",
        "  - Agentes que aprenden: Estos tiene una realimentación de respuesta anteriores para tomar decisiones. Ejemplo: recomendaciones realizadas por un GPS, en función del tipo de rutas más utilizadas por el usuario, en ese horario.\n",
        "\n",
        "6. Para los siguientes entornos de trabajo indique sus **propiedades**:\n",
        "\n",
        "        a. Una partida de ajedrez.\n",
        "         - Totalmente observable. Se tiene información de todas las piezas en todo momento.\n",
        "         - Determinista. El estado siguiente del entorno se puede determinar a partir del actual para cada posible movimiento.\n",
        "         - Secuencial. El agente puede actuar en función de los movimientos previos del otro agente. Dicho de otra manera, los movimientos que se realicen en un instante dado tendrán efecto en una situación posterior en el juego.\n",
        "         - Estático. Mientras el agente está razonando, no se modifican las posiciones de las piezas en el tablero.\n",
        "         - Discreto. Existe un número concreto de posibles movimientos a realizar en cada turno del agente.\n",
        "         - Multiagente. Hay más de un jugador.\n",
        "\n",
        "        b. Un partido de baloncesto. (Considerando que soy un jugador)\n",
        "         - Parcialmente observable. Como jugador no se puede ver todo al mismo tiempo.\n",
        "         - Estocástico. Al hacer un tiro, no se puede determinar con certeza si la pelota va a entrar al aro por ejemplo.\n",
        "         - Secuencial. El actuar de un jugador depende de dónde estuvo en un momento anterior y de dónde estaban los demás jugadores en ese momento.\n",
        "         - Dinámico. Mientras el jugador está pensando su movimiento, el entorno varía dado que, por ejemplo, el resto de los jugadores están en continuo movimiento y el cronómetro del juego no se detiene.\n",
        "         - Contínuo. Existen infinitas posibilidades a partir de lo que se haga con la pelota y lo que hagan los rivales.\n",
        "         - Multiagente. El juego está dado por múltiples agentes: otros jugadores, pelota.\n",
        "\n",
        "        c. El juego Pacman.\n",
        "         - Completamente observable. El jugador tiene información del estado del entorno en todo momento, por ejemplo, se conoce a cada instante la posición de los fantasmas en el laberinto, del pacman, de los puntos, etc.\n",
        "         - Determinista. El estado siguiente depende del estado actual y de las acciones de los agentes. Por ejemplo, es con certeza que al pasar por encima de un punto el pacman lo absorberá\n",
        "         - Secuencial. El jugador puede huir o perseguir a los fantasmas dependiendo si en un momento absorbe un punto de poder que hace vulnerable a los fantasmas. Por otro lado al ser necesario absorber la mayor cantidad de puntos se tratará de ir en una u otra dirección en función de la cantidad de puntos recolectados hasta el momento y de la posición de los puntos restantes en el laberinto.\n",
        "         - Dinámico. Mientras se está pensando hacia dónde mover el pacman, el entorno varía su posición. Por ejemplo los fantasmas se mueven constantemente.\n",
        "         - Discreto. Se conocen todos los posibles movimientos del pacman y de los fantasmas en un estado dado.\n",
        "         - Multiagente. Porque en el laberinto no solo está el agente del jugador sino también los fantasmas\n",
        "\n",
        "        d. El truco.\n",
        "         - Parcialmente observable: No se conocen las cartas del rival.\n",
        "         - Estático: El entorno no cambia mientras el agente piensa la próxima jugada.\n",
        "         - Estocástico: No se conoce con certeza el resultado que tendrá una jugada, hay una probabilidad asociada a que el resultado sea favorable.\n",
        "         - Secuencial: El próximo movimiento depende de las jugadas anteriores. Por ejemplo, el hecho de empardar en primera mano condiciona la carta que se jugará en la proxima mano.\n",
        "         - Discreto: Hay una cantidad finita de jugadas dadas por las reglas del juego. Por ejemplo qué cantar en cada mano, las cartas son una cantidad finita de un maso, etc.\n",
        "         - Multiagente: Hay varios jugadores en cada partido (2, 3, 4, 6).\n",
        "\n",
        "        e. Las damas.\n",
        "         - Totalmente observable. Se tiene información de todas las piezas en todo momento.\n",
        "         - Determinista. La siguiente disposición del tablero se puede determinar a partir de la disposición actual para cada posible movimiento de una pieza.\n",
        "         - Secuencial. Los movimientos de la fichas en un instante dado tendrán efecto en una posterior disposición del tablero, lo que condicionará un posterior movimiento del jugador.\n",
        "         - Estático. Mientras el agente está razonando, no se modifican las posiciones de las piezas en el tablero.\n",
        "         - Discreto. Existe un número concreto de posibles movimientos a realizar en cada turno del agente.\n",
        "         - Multiagente. Hay más de un jugador.\n",
        "\n",
        "        f. El juego tres en raya.\n",
        "         - Totalmente observable. La disposición de marcas en la cuadrícula se conoce en todo momento.\n",
        "         - Determinista. Se sabe con certeza el efecto de poner una cruz/círculo en una u otra posición de la cuadrícula, no hay una probabilidad asociada a las acciones.\n",
        "         - Secuencial. Dado que para ganar el juego es necesario conseguir tres marcas en línea, la posición en la que se coloquen las marcas siguientes dependerá de las marcas realizadas antes tanto por el jugador como por el contrincante.\n",
        "         - Estático. La cuadrícula permanece inerte mientras se decide la próxima acción (suponiendo que se toma una decisión luego de que el contrincante haya completado su turno).\n",
        "         - Discreto. En cada instante el jugador puede colocar una marca en una cantidad límitada de cuadros en la cuadrícula y la cantidad de disposiciones posibles de la cuadrícula también es finita.\n",
        "         - Multiagente. En principio juegan 2 jugadores.\n",
        "\n",
        "        g. Un jugador de Pokémon Go.\n",
        "         - Parcialmente observable. Como jugador no se puede ver todo al mismo tiempo, solo puedo observar lo que se encuentra dentro del rango en el que estoy.\n",
        "         - Estocástico. Al lanzar un tipo de pokebola, no puedo determinar con certeza si voy a atrapar al pokemon o no.\n",
        "         - Secuencial. El actuar depende de cuántas veces tiré anteriormente, de la complejidad del pokemon para atraparlo, entre otras cosas.\n",
        "         - Dinámico. Mientras el jugador está pensando su movimiento, el entorno varía. Por ejemplo, si estoy yendo en micro, demorar mucho podría hacer que el pokemon se escape.\n",
        "         - Contínuo. Existen cantidades infinitas de sucesos que pueden ocurrir en todo momento, como eventos temporales, torneos, etc. A su vez, los desplazamientos no son discretos.\n",
        "         - Multiagente. El juego está dado por múltiples agentes, como otros jugadores, pokemones con probabilidades distintas para aparecer.\n",
        "\n",
        "        h. Un robot explorador autónomo de Marte.\n",
        "         - Parcialmente observable. El robot no podrá ver todo al mismo tiempo, solo podrá observar aquello que se encuentre dentro del rango de visión que permitan sus sensores (para este caso, sus cámaras).\n",
        "         - Estocástico. Al estar en un planeta y entorno desconocido, no se sabrá determinar todo aquello que pueda suceder.\n",
        "         - Secuencial. Las acciones que el robot realice, dependerán de las cosas que hizo anteriormente, de su posición, de su entorno.\n",
        "         - Dinámico. Mientras el robot piensa qué hacer, su entorno se mantiene en constate cambio, como podría ser en el planeta Tierra.\n",
        "         - Contínuo. Existen infinitas posibles combinaciones de acciones a realizar, debido a que se desenvuelve en un territorio \"infinito\".\n",
        "         - Multiagente. A pesar de que en Marte pueda no haber vida biológica, el clima, viento, terrenos, podrían actuar como múltiples agentes que modifiquen el actuar del robot.\n",
        "\n",
        "7. Elabore una tabla REAS para los siguientes entornos de trabajo:\n",
        "\n",
        "        a. Crucigrama.\n",
        "        Medida de Rendimiento: Tiempo en completarlo, correcta completitud.\n",
        "        Entorno: Papel, lapicera, pistas.\n",
        "        Actuadores: elemento de escritura.\n",
        "        Sensores: Ojos.\n",
        "\n",
        "        b. Taxi circulando.\n",
        "        Medida de rendimiento: Cantidad de pasajeros, distancia recorrida, dinero reacudado, cantidad de accidentes.\n",
        "        Entorno: Calles, otros autos, peatones, señales de tránsito.\n",
        "        Actuadores: dirrección, acelador, frenos.\n",
        "        Sensores: velocímetro, GPS, visión, tacómetro, reloj.\n",
        "\n",
        "        c. Robot clasificador de piezas.\n",
        "        Medida de rendimiento: Cantidad de piezas clasificadas correctamente, velocidad a la que realiza la tarea.\n",
        "        Entorno: Lugar donde se ecuentran las piezas, lugar de destino de las mismas.\n",
        "        Actuadores: motores que mueven las articulaciones.\n",
        "        Sensores: Sensor de color, forma, tamaño, proximidad, cámara.\n",
        "\n",
        "<h2>Ejercicios Prácticos\n",
        "\n",
        "8. La Hormiga de Langton es un agente capaz de modificar el estado de la casilla en la que se encuentra para colorearla o bien de blanco o de negro. Al comenzar, la ubicación de la hormiga es una casilla aleatoria y mira hacia una de las cuatro casillas adyacentes. Si...\n",
        "\n",
        "* ... la casilla sobre la que está es blanca, cambia el color del cuadrado, gira noventa grados a la derecha y avanza un cuadrado.\n",
        "\n",
        "* ... la casilla sobre la que está es negra, cambia el color del cuadrado, gira noventa grados a la izquierda y avanza un cuadrado.\n",
        "\n",
        "  Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "\n",
        "  ¿Observa que se repite algún patrón? De ser así, ¿a partir de qué iteración?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8) La Hormiga de Langton es un agente capaz de modificar el estado de la casilla en la que se encuentra para colorearla o bien de blanco o de negro.\n",
        "# Al comenzar, la ubicación de la hormiga es una casilla aleatoria y mira hacia una de las cuatro casillas adyacentes. Si...\n",
        "\n",
        "# ... la casilla sobre la que está es blanca, cambia el color del cuadrado, gira noventa grados a la derecha y avanza un cuadrado.\n",
        "\n",
        "# ... la casilla sobre la que está es negra, cambia el color del cuadrado, gira noventa grados a la izquierda y avanza un cuadrado.\n",
        "\n",
        "#   Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "\n",
        "#    ¿Observa que se repite algún patrón? De ser así, ¿a partir de qué iteración?\n",
        "\n",
        "import pygame #Importamos biblioteca grafica\n",
        "import sys\n",
        "import random #Importamos biblioteca random\n",
        "\n",
        "# Definir las constantes para representar el color de las celdas\n",
        "BLANCO = (255, 255, 255)  # Color blanco en formato RGB\n",
        "NEGRO = (0, 0, 0)        # Color negro en formato RGB\n",
        "\n",
        "# Definir las direcciones posibles: arriba, derecha, abajo, izquierda\n",
        "DIRECCIONES = [(0, -1), (1, 0), (0, 1), (-1, 0)]  # Cambios en (x, y) para cada dirección\n",
        "\n",
        "def langton_hormiga(iteraciones, pantalla, tamaño_celda):\n",
        "    # Definir el tamaño del tablero (ancho y alto en celdas)\n",
        "    tamaño_tablero = 70\n",
        "    # Crear una matriz que representa el tablero, inicializada con celdas blancas\n",
        "    tablero = [[BLANCO] * tamaño_tablero for _ in range(tamaño_tablero)]\n",
        "\n",
        "    # Generar una posición inicial aleatoria para la hormiga dentro del tablero\n",
        "    x = random.randint(0, tamaño_tablero - 1)\n",
        "    y = random.randint(0, tamaño_tablero - 1)\n",
        "\n",
        "    # Inicializar la dirección de la hormiga de forma aleatoria\n",
        "    direccion_actual = random.randint(0, 3)\n",
        "    contador_iteraciones = 0  # Inicializar el contador de iteraciones\n",
        "\n",
        "    # Crear una fuente para el contador de iteraciones en la interfaz gráfica\n",
        "    fuente = pygame.font.Font(None, 36)\n",
        "\n",
        "    # Crear un objeto de reloj para controlar la velocidad de la simulación\n",
        "    reloj = pygame.time.Clock()\n",
        "\n",
        "    # Bucle principal de la simulación\n",
        "    for _ in range(iteraciones):\n",
        "        # Manejar eventos de pygame, como cerrar la ventana\n",
        "        for evento in pygame.event.get():\n",
        "            if evento.type == pygame.QUIT:\n",
        "                pygame.quit()  # Cerrar pygame\n",
        "                sys.exit()     # Salir del programa\n",
        "\n",
        "        # Incrementar el contador de iteraciones en cada ciclo\n",
        "        contador_iteraciones += 1\n",
        "\n",
        "        # Crear el texto para el contador de iteraciones\n",
        "        texto_contador = fuente.render(\"Iteraciones: \" + str(contador_iteraciones), True, NEGRO)\n",
        "\n",
        "\n",
        "        # Cambiar el color y dirección de la celda actual según las reglas de la hormiga\n",
        "        if tablero[y][x] == BLANCO:\n",
        "            tablero[y][x] = NEGRO  # Cambiar celda a negro\n",
        "            direccion_actual = (direccion_actual + 1) % 4  # Girar 90 grados a la derecha\n",
        "        else:\n",
        "            tablero[y][x] = BLANCO  # Cambiar celda a blanco\n",
        "            direccion_actual = (direccion_actual - 1) % 4  # Girar 90 grados a la izquierda\n",
        "        #Se utiliza %4 para trabajar con el resto y evitar que la suma sea infinita.\n",
        "        # Actualizar las coordenadas de la hormiga según la dirección actual\n",
        "        #DIRECCIONES = [(0, -1), (1, 0), (0, 1), (-1, 0)]\n",
        "        dx, dy = DIRECCIONES[direccion_actual]\n",
        "        x = (x + dx) % tamaño_tablero  # Actualizar posición \"x\" con movimiento y ajuste de límites\n",
        "        y = (y + dy) % tamaño_tablero  # Actualizar posición \"y\" con movimiento y ajuste de límites\n",
        "\n",
        "        # Dibujar el estado actual del tablero en la pantalla\n",
        "        pantalla.fill(BLANCO)  # Llenar la pantalla con blanco antes de dibujar el nuevo estado\n",
        "        for i in range(tamaño_tablero):\n",
        "            for j in range(tamaño_tablero):\n",
        "                # Dibujar un rectángulo en la posición correspondiente con el color de la celda\n",
        "                pygame.draw.rect(pantalla, tablero[i][j], (i * tamaño_celda, j * tamaño_celda, tamaño_celda, tamaño_celda))\n",
        "\n",
        "        # Dibujar el contador de iteraciones en la pantalla\n",
        "        pantalla.blit(texto_contador, (10, 10))\n",
        "\n",
        "        pygame.display.flip()  # Actualizar la pantalla con los cambios\n",
        "        reloj.tick(380)  # Limitar la velocidad de la animación a 60 fotogramas por segundo\n",
        "        # Sin el limite de la velocidad el programa grafico crashea.\n",
        "\n",
        "def main():\n",
        "    pygame.init()  # Inicializar pygame\n",
        "\n",
        "    tamaño_celda = 10  # Tamaño de cada celda en píxeles\n",
        "    tamaño_tablero = 70  # Tamaño del tablero en celdas (ancho y alto)\n",
        "    ancho = tamaño_tablero * tamaño_celda\n",
        "    alto = tamaño_tablero * tamaño_celda\n",
        "\n",
        "    pantalla = pygame.display.set_mode((ancho, alto))  # Crear la ventana gráfica\n",
        "    pygame.display.set_caption(\"Hormiga de Langton\")  # Establecer el título de la ventana\n",
        "\n",
        "    iteraciones_totales = 12000\n",
        "    langton_hormiga(iteraciones_totales, pantalla, tamaño_celda)  # Ejecutar la simulación\n",
        "\n",
        "    pygame.quit()  # Cerrar pygame\n",
        "    sys.exit()     # Salir del programa\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "AhJI-HXnClY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h3>Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "<ul>\n",
        "Agente: Hormiga de Langton\n",
        "\n",
        "TABLA REAS\n",
        "\n",
        "| Medida de Rendimiento  | Entorno        | Actuadores                                                                                                         | Sensores                             |\n",
        "|------------------|----------------------------|-------------------------------------------------------------------------------------------------------------------|----------------------------------------|\n",
        "| Densidad de celdas cambiadas, formacion de patrones especificos, distancia a la posicion inicial.    | Tablero, Celda actual.    | Direccion | Color de la celda, dirección actual.  |\n",
        "\n",
        "\n",
        "\n",
        "<h3>PROPIEDADES DEL ENTORNO\n",
        "\n",
        "1. **Total o parcialmente observable.** Parcialmente observable: Desde el punto de vista de la hormiga, se puede considerar parcialmente observable, ya que la misma solo es consciente del estado de la celda en la que se encuentra en ese instante, pero no puede observar todo el tablero.\n",
        "\n",
        "2. **Determinista o estocástico.** Determinista: El comportamiento de la hormiga está completamente determinado por las reglas específicas de cambio de color y giro en función del estado de la celda actual. Solo la posición y la dirección inicial son estocásticas, ya que se designan de forma aleatoria.\n",
        "\n",
        "3. **Episódico o secuencial.** Secuencial: El estado del tablero evoluciona en función de las acciones previas y por ende, las acciones de la hormiga tienen consecuencias a lo largo de múltiples iteraciones.\n",
        "\n",
        "4. **Discreto o continuo.**  Discreto: El entorno está compuesto por un tablero de celdas discretas, donde la hormiga se mueve de una celda a otra en pasos discretos.\n",
        "\n",
        "5. **Estático o dinámico.** Estático: El entorno es estático ya que no cambia en la medida en que la hormiga \"razona\".\n",
        "\n",
        "6. **Agente individual o multiagente.** Agente individual: Se simula una sola hormiga que interactúa con el entorno.\n",
        "\n",
        "<ul>\n",
        "<h3>¿Observa que se repite algún patrón? De ser así, ¿a partir de qué iteración?\n",
        "\n",
        "  Sí, se puede observar que durante este ejercicio se repite un patrón, sin embargo, no se puede garantizar que la Hormiga de Langton siempre genere patrones repetitivos. Esto se debe a que el comportamiento es altamente impredecible y depende de múltiples variables como el tamaño del tablero, la posición inicial de la hormiga y las condiciones iniciales del tablero.\n",
        "  En el caso de nuestro ejemplo programado se puede observar una tendencia a la formación del patrón a partir de 10200 iteraciones.\n",
        "</ul>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "WJoOm-vfC89P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. El Juego de la Vida de Conway consiste en un tablero donde cada casilla representa una célula, de manera que a cada célula le rodean 8 vecinas. Las células tienen dos estados: están *vivas* o *muertas*. En cada iteración, el estado de todas las células se tiene en cuenta para calcular el estado siguiente en simultáneo de acuerdo a las siguientes acciones:\n",
        "\n",
        "* Nacer: Si una célula muerta tiene exactamente 3 células vecinas vivas, dicha célula pasa a estar viva.\n",
        "\n",
        "* Morir: Una célula viva puede morir sobrepoblación cuando tiene más de tres vecinos alrededor o por aislamiento si tiene solo un vecino o ninguno.\n",
        "\n",
        "* Vivir: una célula se mantiene viva si tiene 2 o 3 vecinos a su alrededor.\n",
        "\n",
        "  Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:"
      ],
      "metadata": {
        "id": "KaufPde0jvJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pygame\n",
        "import numpy as np\n",
        "import sys\n",
        "import random\n",
        "\n",
        "# Inicialización de Pygame\n",
        "pygame.init()\n",
        "\n",
        "# Dimensiones de la pantalla\n",
        "SCREEN_WIDTH = 800\n",
        "SCREEN_HEIGHT = 600\n",
        "\n",
        "# Tamaño de celdas\n",
        "CELL_SIZE = 5\n",
        "\n",
        "# Colores\n",
        "WHITE = (255, 255, 255)\n",
        "BLACK = (0, 0, 0)\n",
        "\n",
        "# Creación de la pantalla\n",
        "screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
        "pygame.display.set_caption(\"Juego de la Vida de Conway\")\n",
        "\n",
        "# Función para crear un patrón aleatorio en el tablero\n",
        "def randomize_board(board):\n",
        "    return np.random.randint(2, size=board.shape) # Genera un arreglo de valores aleatorios (0 o 1) con las mismas dimensiones que el tablero\n",
        "\n",
        "# Crear un tablero con celdas aleatorias\n",
        "board = randomize_board(np.zeros((SCREEN_HEIGHT // CELL_SIZE, SCREEN_WIDTH // CELL_SIZE), dtype=int))\n",
        "\n",
        "\n",
        "# Función para calcular el siguiente estado del tablero\n",
        "def next_generation(board):\n",
        "    # Crea una copia del tablero actual para almacenar el siguiente estado\n",
        "    new_board = np.copy(board)\n",
        "\n",
        "    # Itera sobre las celdas internas del tablero\n",
        "    for y in range(1, board.shape[0] - 1):\n",
        "        for x in range(1, board.shape[1] - 1):\n",
        "            # Obtiene la vecindad (3x3) alrededor de la celda actual\n",
        "            neighborhood = board[y-1:y+2, x-1:x+2]\n",
        "\n",
        "            # Cuenta el número de celdas vivas en la vecindad y resta el valor de la celda actual\n",
        "            live_cells = np.count_nonzero(neighborhood) - board[y, x]\n",
        "\n",
        "            # Aplica las reglas del Juego de la Vida\n",
        "            if board[y, x] == 1:\n",
        "                # Si una celda viva tiene menos de 2 o más de 3 vecinos vivos, muere\n",
        "                if live_cells < 2 or live_cells > 3:\n",
        "                    new_board[y, x] = 0\n",
        "            else:\n",
        "                # Si una celda muerta tiene exactamente 3 vecinos vivos, revive\n",
        "                if live_cells == 3:\n",
        "                    new_board[y, x] = 1\n",
        "\n",
        "    # Retorna el nuevo estado del tablero\n",
        "    return new_board\n",
        "\n",
        "# Reloj\n",
        "clock = pygame.time.Clock()\n",
        "\n",
        "# Bucle principal del juego\n",
        "running = True\n",
        "while running:\n",
        "    for event in pygame.event.get():\n",
        "        # Verifica si se ha producido un evento de cierre de ventana\n",
        "        if event.type == pygame.QUIT:\n",
        "            running = False\n",
        "\n",
        "\n",
        "    # Actualizar el tablero\n",
        "    board = next_generation(board)\n",
        "\n",
        "    # Limpieza de la pantalla\n",
        "    screen.fill(WHITE)\n",
        "\n",
        "    # Dibujo de las celdas vivas\n",
        "    for y in range(board.shape[0]):\n",
        "        for x in range(board.shape[1]):\n",
        "            # Verifica si la celda está viva (valor 1) en el tablero\n",
        "            if board[y, x] == 1:\n",
        "                # Dibuja un rectángulo negro en las coordenadas (x, y) de la celda en la pantalla\n",
        "                pygame.draw.rect(screen, BLACK, (x * CELL_SIZE, y * CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
        "\n",
        "    # Actualiza la pantalla\n",
        "    pygame.display.update()\n",
        "\n",
        "    # Limita la velocidad de actualización a 10 fotogramas por segundo\n",
        "    clock.tick(10)\n",
        "\n",
        "pygame.quit()  # Cerrar pygame\n",
        "sys.exit()     # Salir del programa"
      ],
      "metadata": {
        "id": "ecDVwGTCXFEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "<ul>\n",
        "Agente: Juego de la Vida de Conway\n",
        "\n",
        "TABLA REAS:\n",
        "\n",
        "| Medida de Rendimiento  | Entorno | Actuadores | Sensores |\n",
        "|------------------------|---------|------------|----------|\n",
        "| Formación de bloques que no propagan actividad ni se desplazan | Tablero | Dar vida o muerte a las células | Estado de las células, posicionamiento.|\n",
        "\n",
        "<h3>PROPIEDADES DEL ENTORNO\n",
        "\n",
        "1. **Total o parcialmente observable.** Totalmente observable: Desde el punto de vista del agente, que cambia el estado de las células de acuerdo a las reglas definidas en el juego. Sus sensores permiten determinar el estado de vida o muerte de cada una de las células y la posisión absoluta de cada una de ellas en el tablero, así como también la posición relativa de las células.\n",
        "\n",
        "2. **Determinista o estocástico.** Determinista: El siguiente estado del tablero está completamente determinado por el estado actual del mismo y las reglas del juego. La disposición inicial del tablero sí es aleatoria.\n",
        "\n",
        "3. **Episódico o secuencial.** Secuencial: El estado del tablero en un instante dado es resultado de la evolución del mismo en instantes pasados y el estado presente tendrá influencia en una disposición futura del tablero.\n",
        "\n",
        "4. **Discreto o continuo.**  Discreto: El tablero está discretizado en celdas que pueden ocupar las células, el estado de estas células es discreto, hay una cantidad finita (aunque sea muy grande) de estados posibles del tablero.\n",
        "\n",
        "5. **Estático o dinámico.** Estático: El entorno permanece inerte durante el procesamiento del agente.\n",
        "\n",
        "6. **Agente individual o multiagente.** Agente individual: Desde el punto de vista de quien controla el estado del tablero a cada instante. Si se observa desde el punto de vista de las célula, la caracterización sería multiagente y cada célula sería un agente.\n",
        "</ul>"
      ],
      "metadata": {
        "id": "VlrAS6cxmat5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXcAF__NmgG5"
      },
      "source": [
        "# Bibliografía\n",
        "\n",
        "[Russell, S. & Norvig, P. (2004) _Inteligencia Artificial: Un Enfoque Moderno_. Pearson Educación S.A. (2a Ed.) Madrid, España](https://www.academia.edu/8241613/Inteligencia_Aritificial_Un_Enfoque_Moderno_2da_Edici%C3%B3n_Stuart_J_Russell_y_Peter_Norvig)\n",
        "\n",
        "[Poole, D. & Mackworth, A. (2017) _Artificial Intelligence: Foundations of Computational Agents_. Cambridge University Press (2a Ed.) Vancouver, Canada](http://artint.info/2e/html/ArtInt2e.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}